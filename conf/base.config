/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    sanger-tol/ascc Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/

process {

    cpus   = { 1      * task.attempt        }
    memory = { 6.GB   * task.attempt        }
    time   = { 4.h    * task.attempt        }

    errorStrategy = { task.exitStatus in ((130..145) + 104 + 175) ? 'retry' : 'finish' }
    maxRetries    = 1
    maxErrors     = '-1'


    // PIPELINE NESTING
    withName: 'SANGER_TOL_BTK|SANGER_TOL_BTK_CASCADE' {
        memory  = { 1200.MB * task.attempt    }
        time    = { 96.h    * task.attempt    }
    }

    // BLAST RELATED MODULES WHICH WILL NEED THE MOST RESOURCES
    withName: 'BLAST_BLASTN|BLAST_BLASTN_MOD|DIAMOND_BLASTX' {
        cpus    = { 16                          }
        memory  = { def refSize = reference.size()
                    30.GB  * (
                                (
                                    refSize < 2e9 ? 1 : (
                                        refSize < 5e9 ? 3 : (
                                            refSize < 10e9 ? 8 : 12
                                        )
                                    )
                                ) * task.attempt
                            )
                        }
        time    = { 22.h     * task.attempt     }
    }

    withName: ".*:(PLASTID|MITO)_ORGANELLAR_BLAST:BLAST_BLASTN" {
        cpus   = { 20   * 1 }
        memory = { 10.GB * ( task.attempt * 10 ) }
        time   = { 1.h  * ( reference.size() < 1e9 ? 10 : 20 ) }
    }

    withName: ".*:(PLASTID|MITO)_ORGANELLAR_BLAST:PACBIO_BARCODE_CHECK:BLAST_BLASTN" {
        cpus   = { 20   * 1 }
        memory = { 10.GB * ( task.attempt ) }
        time   = { 1.h  * ( reference.size() < 1e9 ? 10 : 20 ) }
    }

    withName: 'SAMTOOLS_DEPTH_AVERAGE_COVERAGE' {
        memory  = { 500.MB    * task.attempt     }
    }


    // FCS REQUIRES LOADING THE WHOLE FCS DB INTO MEMORY AT ONE TIME
    withName: 'FCSGX_RUNGX' {
        cpus    = { 32      }
        memory  = { 520.GB  }
        time    = { 12.h    }
    }

    withName: ".*:GENOMIC:RUN_READ_COVERAGE:SE_MAPPING:MINIMAP2_ALIGN_SE" {
        cpus   = { 20   * 1 }
        memory = {
            def refSize = reference.size()
            1.GB * (
                refSize < 2e9 ? 30 : (
                    refSize < 5e9 ? 40 : (
                        refSize < 10e9 ? 60 :
                        // 14Gb genome * 15 should result in significantly higher
                        // allocation than 60 or genome * 3
                        Math.ceil(
                            (refSize / 1e9) * 15
                        )
                    )
                )
            ) * task.attempt
        }
        time   = {
            def refSize = reference.size()
            1.h  * ( refSize < 1e9 ? 10 : refSize < 10e9 ? 30 : 48)
        }
    }


    withName: ".*:ORGANELLAR:RUN_READ_COVERAGE:MINIMAP2_ALIGN_SE" {
        cpus   = { 20   * 1 }
        memory = { 1.GB * ( task.attempt * 10 ) }
        time   = { 1.h  * ( reference.size() < 1e9 ? 10 : 20 ) }
    }

    // SAMTOOLS MODULES WILL NEED A REVISIT DUE, THESE ARE DEFAULTS
    // IN CASES WHERE THERE IS ONE HIC FILE THIS WILL NEED ALMOST NOTHING
    withName:SAMTOOLS_MERGE {
        cpus    = { 16                          }
        memory  = { 50.GB     * task.attempt    }
    }

    withName:SAMTOOLS_SORT {
        cpus    = { 16                          }
        memory  = { 50.GB     * task.attempt    }
    }

    withName:SAMTOOLS_DEPTH {
        cpus    = { 16                          }
        memory  = { 50.GB     * task.attempt    }
    }

    // PYTHON BASED MODULES WHICH SHOULDN'T NEED MORE THAN 1 CORE AND A MIDDLING AMOUNT OF MEMORY
    // WILL BE REVIEWED
    withName: 'VALIDATE_TAXID|TRAILINGNS|GC_CONTENT|GET_KMERS_PROFILE|PARSE_FCSGX_RESULT|ASCC_MERGE_TABLES|GET_LARGEST_SCAFF|KMER_COUNT_DIM_REDUCTION|KMER_COUNT_DIM_REDUCTION_COMBINE_CSV|REFORMAT_DIAMOND_OUTFMT6|CONVERT_TO_HITS_FILE|DIAMOND_BLAST_CHUNK_TO_FULL|GENERATE_SAMPLESHEET' {
        cpus    = { 1                           }
        memory  = { 10.GB    * task.attempt     }
        time    = { 5.h      * task.attempt     }
    }

    withName:GET_KMER_COUNTS {
        // 200mb genome becomes a 2.2 modifier
        // 2.2 * 15Gb * task.attempt
        // 1Gb genome becomes a 3x modifier
        // etc
        // FOR TESTING -- This likely is not the correct calculation for memory
        // This will be memory profiled
        cpus    = { 1                           }
        memory  = { (Math.ceil(fasta.size() / 1e9 + 2) * 15.GB) * task.attempt }
        time    = { 5.h      * task.attempt     }
    }

    withName:KRAKEN2_KRAKEN2 {
        // Scalling based on the size of the input genome.
        cpus   = { 12        * task.attempt     }
        memory = { 72.GB     * task.attempt     }
        time   = { 16.h      * task.attempt     }
    }

    withName:TIARA_TIARA {
        // 1GB genome = 20 * 1 * attempt    // 20 -- 40 -- 60
        // 3GB genome = 20 * 3 * attempt    // 60 -- 120 -- 180
        // 10GB genome = 20 * 100 * attempt // 200 -- 400 -- 600
        cpus   = { 12 }
        memory = { 20.GB  * (( fasta.size() < 1e9 ? 1 : fasta.size() < 5e9 ? 3 : 10) * task.attempt) }
        time   = { 20.h   * task.attempt }
    }


    // Process-specific resource requirements
    // NOTE - Please try and reuse the labels below as much as possible.
    //        These labels are used and recognised by default in DSL2 files hosted on nf-core/modules.
    //        If possible, it would be nice to keep the same label naming convention when
    //        adding in your local modules too.
    // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
    withLabel:process_single {
        cpus   = { 1                   }
        memory = { 6.GB * task.attempt }
        time   = { 4.h  * task.attempt }
    }

    withLabel:process_low {
        cpus   = { 2     * task.attempt }
        memory = { 12.GB * task.attempt }
        time   = { 4.h   * task.attempt }
    }

    withLabel:process_medium {
        cpus   = { 6     * task.attempt }
        memory = { 36.GB * task.attempt }
        time   = { 8.h   * task.attempt }
    }

    withLabel:process_high {
        cpus   = { 12    * task.attempt }
        memory = { 72.GB * task.attempt }
        time   = { 16.h  * task.attempt }
    }

    withLabel:process_long {
        time   = { 20.h  * task.attempt }
    }

    withLabel:process_high_memory {
        memory = { 200.GB * task.attempt }
    }

    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }

    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 2
    }
    withLabel: process_gpu {
        ext.use_gpu = { workflow.profile.contains('gpu') }
    }
}
