nextflow_pipeline {

    // Full pipeline test minus the sanger-tol/blobtoolkit nested pipeline module
    // Module is long running and already tested via it's own CICD.
    // The test would be nice to include due to downstream parsing, however
    // it is difficult to justify.

    name "Test pipeline (NO BLOBTOOLKIT)"
    script "../main.nf"
    tag "pipeline"

    test("-profile test") {

        setup {
            // Data and Databases: that use curl | tar
            // For loop as the data is all treated the same

            def database_dict = [
                                    "TEST_DATA" : [
                                        "URL": "https://tolit.cog.sanger.ac.uk/test-data/resources/ascc/asccTinyTest_V2.tar.gz",
                                        "OUT": "asccTinyTest_V2"
                                    ],
                                    "BLASTN" : [
                                        "URL": "https://dp24.cog.sanger.ac.uk/blastn.tar.gz",
                                        "OUT": "blastn"
                                    ],
                                    "BUSCO_LINEAGES" :  [
                                        "URL": "https://tolit.cog.sanger.ac.uk/test-data/resources/busco/blobtoolkit.GCA_922984935.2.2023-08-03.lineages.tar.gz",
                                        "OUT": "busco_database"
                                    ],
                                    "KRAKEN2" :         [
                                        "URL": "https://raw.githubusercontent.com/nf-core/test-datasets/modules/data/genomics/sarscov2/genome/db/kraken2.tar.gz",
                                        "OUT": "kraken2"
                                    ],
                                    "NT_SUBSET" :       [
                                        "URL": "https://ftp.ncbi.nlm.nih.gov/blast/db/18S_fungal_sequences.tar.gz",
                                        "OUT": "NT_database"
                                    ],
                                    "VECSCREEN" :       [
                                        "URL": "https://ftp.ncbi.nlm.nih.gov/blast/db/v4/16SMicrobial_v4.tar.gz",
                                        "OUT": "vecscreen"
                                    ]
                                ]


            for (String dbKey : database_dict.keySet()) {
                def db = database_dict.get(dbKey)
                new File("${projectDir}/${dbKey}").mkdir()

                println "\nDownloading the database ${dbKey}..."
                def command = ['bash', '-c', "curl ${db['URL']} | tar xzf - -C ${projectDir}/${dbKey}/"]
                def process = command.execute()
                process.waitFor()

                if (process.exitValue() != 0) {
                    throw new RuntimeException("Error - failed to download ${dbKey}: ${process.err.text}")
                }

                println "Done"
            }

            // Copy the test data so that we have a fake haplo
            def data_copy_command = ['bash', '-c', "cp ${projectDir}/TEST_DATA/asccTinyTest_V2/assembly/pyoelii_tiny_testfile_with_adapters.fa ${projectDir}/TEST_DATA/asccTinyTest_V2/assembly/Pyoeliiyoelii17XNL_assembly_hap.fa"]
            def data_copy_proc = data_copy_command.execute()
            data_copy_proc.waitFor()

            // Databases: FCS DATABASE
            def fcs_database = [
                "FCS1" : [
                    "FILE": "test-only.taxa.tsv",
                    "OUT" : "all.taxa.tsv"
                ],
                "FCS2" : [
                    "FILE": "test-only.gxi",
                    "OUT": "all.gxi"
                ],
                "FCS3" : [
                    "FILE": "test-only.gxs",
                    "OUT": "all.gxs"
                ],
                "FCS4" : [
                    "FILE": "test-only.meta.jsonl",
                    "OUT": "all.meta.jsonl"
                ],
                "FCS5" : [
                    "FILE": "test-only.blast_div.tsv.gz",
                    "OUT": "all.blast_div.tsv.gz"
                ]
            ]

            new File("${projectDir}/FCS_gx").mkdir()

            for (String dbKey : fcs_database.keySet()) {
                def db = fcs_database.get(dbKey)

                println "\nDownloading the FCS file: ${db['FILE']}..."
                def command2 = ['bash', '-c', "wget -cq https://ftp.ncbi.nlm.nih.gov/genomes/TOOLS/FCS/database/test-only/${db['FILE']} -O ${projectDir}/FCS_gx/${db['OUT']}"]
                def process2 = command2.execute()
                process2.waitFor()

                if (process2.exitValue() != 0) {
                    throw new RuntimeException("Error - failed to download ${dbKey}: ${process2.err.text}")
                }

                println "Done"
            }

            // Databases: The wierd ones

            new File("${projectDir}/NCBI_TAXONOMY").mkdir()
            new File("${projectDir}/DIAMOND").mkdir()
            def other_dbs = [
                "NCBI_TAXONOMY_DB": [
                    "COMMAND":
                        "curl -L --retry 5 --retry-delay 10 https://ftp.ncbi.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.tar.gz --output new_taxdump.tar.gz && tar -C ${projectDir}/NCBI_TAXONOMY -xzf new_taxdump.tar.gz"
                ],
                "ASCC_DIAMOND_DB": [
                    "COMMAND":
                        "curl https://dp24.cog.sanger.ac.uk/ascc/diamond.dmnd -o ${projectDir}/DIAMOND/diamond.dmnd"
                ]
            ]

            for (String dbKey : other_dbs.keySet()) {
                def db = other_dbs.get(dbKey)

                println "\nDownloading the OTHER DB's: ${dbKey}..."
                def command3 = ['bash', '-c', "${db['COMMAND']}"]
                def process3 = command3.execute()
                process3.waitFor()

                if (process3.exitValue() != 0) {
                    throw new RuntimeException("Error - failed to download ${dbKey}: ${process3.err.text}")
                }

                println "Done"
            }

            String result = "ls -lha ".execute().text
            println result.toUpperCase()

        }

        when {
            params {
                outdir = "$outputDir"
            }
        }

        then {
            // stable_name: All files + folders in ${params.outdir}/ with a stable name
            def stable_name = getAllFilesFromDir(params.outdir, relative: true, includeDir: true, ignore: ['pipeline_info/*.{html,json,txt}'])

            // stable_path: All files in ${params.outdir}/ with stable content
            def stable_path = getAllFilesFromDir(params.outdir, ignoreFile: 'tests/.nftignore')

            // stable_name: sorted per subworkflow output directory
            // output for ascc exists across n (= number of input assemblies) directories and so the tests need to also reflect this.

            // First block are files which will only be found in PRIMARY or HAPLO files
            // due to these processes existing only in the GENOMIC subworkflow
            def ascc_main_output    = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_{HAPLO,PRIMARY}/ascc_main_output/*contamination_check_merged_table.csv"])
            def autofilter_files    = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_{HAPLO,PRIMARY}/autofilter/*autofiltered.fasta"])
            def autofilter_txt      = getAllFilesFromDir(params.outdir, include: [
                                            "asccTinyTest_V2_{HAPLO,PRIMARY}/autofilter/*autofiltered.csv",
                                            "asccTinyTest_V2_{HAPLO,PRIMARY}/autofilter/*autofiltered.txt"
                                        ])
            def kmer_data_files     = getAllFilesFromDir(params.outdir, include: [
                                            "asccTinyTest_V2_{HAPLO,PRIMARY}/kmer_data/*KMER_COUNTS.csv",
                                            "asccTinyTest_V2_{HAPLO,PRIMARY}/kmer_data/*combined.csv"
                                        ])
            def autofilter_warn_txt = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_{HAPLO,PRIMARY}/autofilter_done_indicator_file.txt"])
            def generate_samplesheet= getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_{HAPLO,PRIMARY}/generate_samplesheet/*csv"])

            // Everything Else (Not GENOMIC specific)
            def create_btk_dataset  = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/create_btk_dataset/btk_datasets_CBD/*.{yaml,json}"])
            def create_btk_tsv      = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/create_btk_dataset/*.tsv"])
            def fcs_adaptor_euk     = getAllFilesFromDir(params.outdir, include: [
                                            "asccTinyTest_V2_*/fcs_adaptor/*_euk.*.fa.gz",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_euk.*.log",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_euk.*.txt",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_euk.*.yaml",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_euk.*.jsonl"
                                        ])
            def fcs_adaptor_prok    = getAllFilesFromDir(params.outdir, include: [
                                            "asccTinyTest_V2_*/fcs_adaptor/*_prok.*.fa.gz",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_prok.*.log",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_prok.*.txt",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_prok.*.yaml",
                                            "asccTinyTest_V2_*/fcs_adaptor/*_prok.*.jsonl"
                                        ])
            def fcsgx_data          = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/fcsgx_data/*.{txt,rpt,csv}"])  // <--
            def filter_brcde_bc2001 = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/filter_barcode/*bc2001_filtered.txt"])
            def filter_brcde_bc2009 = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/filter_barcode/*bc2009_filtered.txt"])
            def filtered_fasta      = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/filtered_fasta/*filtered.fasta"])
            def gc_content_files    = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/gc_content/*GC_CONTENT.txt"])
            def kraken2_files       = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/KRAKEN2/*.txt"])
            def summarise_vecscreen = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/summarise_vecscreen_output/*vecscreen_contamination"])
            def tiara_raw_files     = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/tiara_raw_output/*.txt"])
            def trailingns          = getAllFilesFromDir(params.outdir, include: ["asccTinyTest_V2_*/trailingns/*_trim_Ns"])

            // Pipeline completion file, needed for Sanger internal processes
            def completion_file     = getAllFilesFromDir(params.outdir, include: ["workflow_completed.txt"])

            assertAll(
                { assert workflow.success},
                { assert snapshot(
                    // Number of successful tasks
                    workflow.trace.succeeded().size(),

                    // pipeline versions.yml file for multiqc from which Nextflow version is removed because we test pipelines on multiple Nextflow versions
                    removeNextflowVersion("$outputDir/pipeline_info/ascc_software_versions.yml"),

                    // All stable path name, with a relative path
                    stable_name,

                    // GENOMIC only workflow output
                    ascc_main_output,
                    ascc_main_output.size() == 2,

                    autofilter_files,
                    autofilter_files.size() == 2,

                    kmer_data_files,
                    kmer_data_files.size() == 4,

                    autofilter_txt,                 // Autofilter report files
                    autofilter_txt.size() == 4,

                    autofilter_warn_txt,            // Autofilter warn file
                    autofilter_warn_txt.size() == 2,

                    generate_samplesheet,
                    generate_samplesheet.size() == 2,

                    // Everything not specific for GENOMIC
                    // sizes have been written to show that there are X numbers across the 3 input assemblies
                    create_btk_dataset,
                    create_btk_dataset.size() == (15 * 3),
                    create_btk_tsv,
                    create_btk_tsv.size() == (1 * 3),
                    fcs_adaptor_euk,
                    fcs_adaptor_euk.size() == (5 * 3),
                    fcs_adaptor_prok,
                    fcs_adaptor_prok.size() == (5 * 3),
                    fcsgx_data,
                    fcsgx_data.size() == (4 * 3),
                    filter_brcde_bc2001,
                    filter_brcde_bc2001.size() == (1 * 3),
                    filter_brcde_bc2009,
                    filter_brcde_bc2001.size() == (1 * 3),
                    filtered_fasta,
                    filtered_fasta.size() == (1 * 3),
                    gc_content_files,
                    gc_content_files.size() == (1 * 3),
                    kraken2_files,
                    kraken2_files.size() == (3 * 3),
                    summarise_vecscreen,
                    summarise_vecscreen.size() == (1 * 3),
                    tiara_raw_files,
                    tiara_raw_files.size() == (2 * 3),
                    trailingns,
                    trailingns.size() == (1 * 3),

                    // Workflow completion file
                    completion_file,
                    completion_file.size() == 1,

                    // All files with stable contents
                    stable_path,

                    completion_file
                ).match() }
            )
        }

        cleanup {
            new File("${projectDir}/FCS_gx").deleteDir()
            new File("${projectDir}/BLASTN").deleteDir()
            new File("${projectDir}/BUSCO_LINEAGES").deleteDir()
            new File("${projectDir}/TEST_DATA").deleteDir()
            new File("${projectDir}/NCBI_TAXONOMY").deleteDir()
            new File("${projectDir}/NT_SUBSET").deleteDir()
            new File("${projectDir}/KRAKEN2").deleteDir()
            new File("${projectDir}/VECSCREEN").deleteDir()
            new File("${projectDir}/DIAMOND").deleteDir()
            new File("${workDir}").deleteDir()
        }
    }
}
